{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "\n",
    "base_url = r'/home/amit/DataScienceProject/PredictDroughts/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation to Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(base_url + 'files/merge.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate date to year, month and day\n",
    "\n",
    "df['Week'] = pd.to_datetime(df['Week'])\n",
    "set_year = df['Week'].dt.year.to_list()\n",
    "set_month = df['Week'].dt.month.to_list()\n",
    "set_day = df['Week'].dt.day.to_list()\n",
    "df.insert(0, \"Year\", set_year, None)\n",
    "df.insert(1, \"Month\", set_month, None)\n",
    "df.insert(2, \"Day\", set_day, None)\n",
    "df = df.drop(columns='Week', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding on level column\n",
    "\n",
    "encoding_columns = pd.get_dummies(df['LEVEL'], prefix=\"level\")\n",
    "df = df.join(encoding_columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the objects (string) type and Train X\n",
    "\n",
    "X = df[df.columns[(df.columns != 'LEVEL') & (df.columns != 'State') & (df.columns != 'Postal Code') & (df.columns != 'Aland_SQMI')]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['LEVEL']]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% train, 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "models = [\"KNeighborsClassifier\", \"LogisticRegression\", \"DecisionTreeClassifier\", \"SVC\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy on train and test set\n",
    "\n",
    "k_s=[]\n",
    "train_accuracies=[]\n",
    "test_accuracies=[]\n",
    "for k in range(1,21):\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "    y_pred_train=clf.predict(X_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    k_s.append(k)\n",
    "    train_accuracies.append(metrics.accuracy_score(y_true=y_train, y_pred=y_pred_train))\n",
    "    test_accuracies.append(metrics.accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "df=pd.DataFrame({\"k\":k_s,\"train_accuracy\":train_accuracies,\"test_accuracy\":test_accuracies})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation - get the best score\n",
    "\n",
    "parameters = {'n_neighbors':range(1,25,2) }\n",
    "knn = KNeighborsClassifier()\n",
    "clf = GridSearchCV(knn, parameters,scoring=make_scorer(metrics.accuracy_score, greater_is_better=True))\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(\"best parameter set is:\", clf.best_params_, \" and its score was\", clf.best_score_)\n",
    "score_list.append(clf.best_score_ * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression().fit(X_train, y_train.values.ravel())\n",
    "score = lg.score(X_test, y_test) * 100\n",
    "print(score)\n",
    "score_list.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest =  DecisionTreeClassifier(bootstrap=True, n_estimators=300, random_state=0)\n",
    "trained_forest = forest.fit(X_train, y_train.values.ravel()) \n",
    "\n",
    "y_pred_train = trained_forest.predict(X_train)\n",
    "y_pred = trained_forest.predict(X_test)\n",
    "print('Accuracy on training data = ', metrics.accuracy_score(y_true=y_train, y_pred=y_pred_train))\n",
    "print('Accuracy on test data = ', metrics.accuracy_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[2], \"min_samples_split\":[20]}\n",
    "clf = GridSearchCV(forest, parameters,scoring=make_scorer(metrics.accuracy_score, greater_is_better=True))\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "print(\"best parameter set is: \",clf.best_params_,\" and its score was \",clf.best_score_)\n",
    "score_list.append(clf.best_score_ * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC().fit(X_train, y_train)\n",
    "SVM_score = SVM.score(X_test, y_test.values.ravel()) * 100\n",
    "score_list.append(SVM_score)\n",
    "\n",
    "y_pred_train = SVM.predict(X_train)\n",
    "y_pred = SVM.predict(X_test)\n",
    "print('Accuracy on training data = ', metrics.accuracy_score(y_true=y_train, y_pred=y_pred_train))\n",
    "print('Accuracy on test data = ', metrics.accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "print('Accuracy score = ', SVM_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Model\": models,\n",
    "    \"Score\": score_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(data)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(\"Score\", \"Model\", data=score_df, palette=\"Set3\", orient = \"h\")\n",
    "g = g.set_title(\"Cross validation scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Decision Tree classifier have 91.7% accurate More then every models that we used,\n",
    "So for us Decision Tree classifier is the best model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('env': venv)",
   "name": "python385jvsc74a57bd04a89485c9fa54da4c77b5cf4efc6cdf3655d80b063f8257e65d9a52a94defee6"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "4a89485c9fa54da4c77b5cf4efc6cdf3655d80b063f8257e65d9a52a94defee6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}